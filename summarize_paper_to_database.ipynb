{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# import a paper from Zotero, extract data, save to database\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## proof of concept - summarize each paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed folder 'Khaldi et al., 2016' and appended summary to CSV.\n",
      "Processed folder 'Khodagholy et al., 2011' and appended summary to CSV.\n",
      "Processed folder 'Middya et al., 2021' and appended summary to CSV.\n",
      "Processed folder 'Middya et al., 2025' and appended summary to CSV.\n",
      "Processed folder 'Sessolo et al., 2013' and appended summary to CSV.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve your OpenAI API key from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the path to your _inbox folder\n",
    "INBOX_PATH = r\"D:\\OneDrive\\_Carnegie Mellon (CMU)\\60 Academic\\63 Literature Review\\63.002 Literature Review Exports from Zotero\\_inbox\"\n",
    "\n",
    "# OpenAI API endpoint for Chat Completions\n",
    "OPENAI_URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "# Define the output CSV file path\n",
    "CSV_FILE = r\"literature_data\\summaries.csv\"\n",
    "\n",
    "def generate_summary(paper_text):\n",
    "    \"\"\"\n",
    "    Sends the content of paper.txt to the OpenAI Chat Completions endpoint\n",
    "    and returns a summary of the paper. Includes error handling to check\n",
    "    for unexpected API responses.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "    }\n",
    "    prompt_messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are given the full text of a research paper. \"\n",
    "                \"Summarize the paper according to the following instructions: \"\n",
    "                \"1) Provide a concise abstract-like summary. \"\n",
    "                \"2) Highlight the main contributions and conclusions. \"\n",
    "                \"3) Use clear and accessible language. \"\n",
    "                \"Make sure the summary captures the essence of the paper.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": paper_text\n",
    "        }\n",
    "    ]\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": prompt_messages,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    response = requests.post(OPENAI_URL, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Debug: Print the full response if \"choices\" is not found\n",
    "    if \"choices\" not in data:\n",
    "        print(\"Error: Unexpected API response format:\")\n",
    "        print(data)\n",
    "        # Return an empty string or handle as needed\n",
    "        return \"\"\n",
    "    \n",
    "    return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def append_summary_to_csv(folder_name, summary):\n",
    "    \"\"\"\n",
    "    Appends the folder name and summary to a CSV file.\n",
    "    If the file does not exist, it creates one with a header.\n",
    "    \"\"\"\n",
    "    file_exists = os.path.exists(CSV_FILE)\n",
    "    with open(CSV_FILE, \"a\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # Write header if file is new\n",
    "        if not file_exists:\n",
    "            writer.writerow([\"Folder\", \"Summary\"])\n",
    "        writer.writerow([folder_name, summary])\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(INBOX_PATH):\n",
    "        print(f\"Inbox path does not exist: {INBOX_PATH}\")\n",
    "        return\n",
    "\n",
    "    # List all folders in the _inbox\n",
    "    folder_names = [\n",
    "        folder for folder in os.listdir(INBOX_PATH)\n",
    "        if os.path.isdir(os.path.join(INBOX_PATH, folder))\n",
    "    ]\n",
    "\n",
    "    for folder in folder_names:\n",
    "        folder_path = os.path.join(INBOX_PATH, folder)\n",
    "        paper_file = os.path.join(folder_path, \"paper.txt\")\n",
    "\n",
    "        if not os.path.exists(paper_file):\n",
    "            print(f\"Missing paper.txt in folder: {folder}\")\n",
    "            continue\n",
    "\n",
    "        with open(paper_file, \"r\", encoding=\"utf-8\") as pf:\n",
    "            paper_text = pf.read()\n",
    "\n",
    "        # Generate the summary using OpenAI\n",
    "        summary = generate_summary(paper_text)\n",
    "        \n",
    "        # Append the summary to the CSV file\n",
    "        append_summary_to_csv(folder, summary)\n",
    "        print(f\"Processed folder '{folder}' and appended summary to CSV.\")\n",
    "        \n",
    "        # Wait for 6 seconds before processing the next folder\n",
    "        time.sleep(6)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trial 1 - try to sport paper by specific metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed folder 'Khaldi et al., 2016' and appended analysis to CSV.\n",
      "Processed folder 'Khodagholy et al., 2011' and appended analysis to CSV.\n",
      "Processed folder 'Middya et al., 2021' and appended analysis to CSV.\n",
      "Processed folder 'Middya et al., 2025' and appended analysis to CSV.\n",
      "Processed folder 'Sessolo et al., 2013' and appended analysis to CSV.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve your OpenAI API key from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the path to your _inbox folder and the output CSV file path\n",
    "INBOX_PATH = r\"D:\\OneDrive\\_Carnegie Mellon (CMU)\\60 Academic\\63 Literature Review\\63.002 Literature Review Exports from Zotero\\_inbox\"\n",
    "CSV_FILE = r\"literature_data\\literature_database_v1.csv\"\n",
    "\n",
    "# OpenAI API endpoint for Chat Completions\n",
    "OPENAI_URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "# Dictionaries of materials and characterization methods\n",
    "electrode_materials_tally = {\n",
    "    \"Polyethylene Terephthalate (PET)\": 2,\n",
    "    \"Parylene (Parylene-C, Parylene-HT)\": 7,\n",
    "    \"Polyimide (PI)\": 3,\n",
    "    \"SU-8 Photoresist\": 4,\n",
    "    \"Silicon (Si)\": 4,\n",
    "    \"PDMS (Polydimethylsiloxane)\": 2,\n",
    "    \"Gold\": 5,\n",
    "    \"Platinum (Pt)\": 5,\n",
    "    \"Graphene\": 3,\n",
    "    \"Carbon Nanotubes (CNTs)\": 3,\n",
    "    \"Indium Tin Oxide (ITO)\": 2,\n",
    "    \"Titanium (Ti)\": 2,\n",
    "    \"Silver\": 1,\n",
    "    \"PEDOT:PSS\": 4,\n",
    "    \"Nickel\": 1,\n",
    "    \"Aluminum\": 1,\n",
    "    \"Eutectic Gallium–Indium Alloy (EGaIn)\": 1,\n",
    "    \"Chromium (Cr)\": 3,\n",
    "    \"Polycarbonate (PC)\": 1,\n",
    "    \"Styrene-Ethylene-Butylene-Styrene (SEBS)\": 1,\n",
    "    \"Pluronic P123\": 1,\n",
    "    \"Mesoporous Silica Nanoparticles\": 1,\n",
    "    \"Gold Nanorods\": 1,\n",
    "    \"Tungsten\": 1,\n",
    "    \"ZnO Nanowires\": 1,\n",
    "    \"Pyrolytic Carbon\": 2,\n",
    "}\n",
    "\n",
    "functional_electrode_materials = {\n",
    "    \"Gold\": 5,\n",
    "    \"Platinum (Pt)\": 5,\n",
    "    \"Graphene\": 3,\n",
    "    \"Carbon Nanotubes (CNTs)\": 3,\n",
    "    \"Indium Tin Oxide (ITO)\": 2,\n",
    "    \"Titanium (Ti)\": 2,\n",
    "    \"Silver\": 1,\n",
    "    \"PEDOT:PSS\": 4,\n",
    "    \"Nickel\": 1,\n",
    "    \"Aluminum\": 1,\n",
    "    \"Eutectic Gallium–Indium Alloy (EGaIn)\": 1,\n",
    "    \"Chromium (Cr)\": 3,\n",
    "    \"Pluronic P123\": 1,\n",
    "    \"Mesoporous Silica Nanoparticles\": 1,\n",
    "    \"Gold Nanorods\": 1,\n",
    "    \"Tungsten\": 1,\n",
    "    \"ZnO Nanowires\": 1,\n",
    "    \"Pyrolytic Carbon\": 2\n",
    "}\n",
    "\n",
    "benchtop_characterization = {\n",
    "    \"SEM Imaging\": 5,\n",
    "    \"AFM (Atomic Force Microscopy)\": 2,\n",
    "    \"XRD (X-ray Diffraction)\": 1,\n",
    "    \"Raman Spectroscopy\": 2,\n",
    "    \"Optical Transparency Measurements\": 4,\n",
    "    \"Mechanical Testing (e.g., bending, strain)\": 4,\n",
    "    \"Photoluminescence Measurements\": 1,\n",
    "    \"Spatial Resolution Testing (Microscopy)\": 3\n",
    "}\n",
    "\n",
    "def analyze_paper(paper_text):\n",
    "    \"\"\"\n",
    "    Sends the paper text to the OpenAI API with a prompt instructing the model to produce a JSON output.\n",
    "    The JSON includes a summary, dictionaries for electrode materials, functional electrode materials,\n",
    "    benchtop characterization, and an impedance value if available.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "    }\n",
    "    \n",
    "    electrode_keys = list(electrode_materials_tally.keys())\n",
    "    functional_keys = list(functional_electrode_materials.keys())\n",
    "    characterization_keys = list(benchtop_characterization.keys())\n",
    "    \n",
    "    prompt_text = (\n",
    "        \"You are given the full text of a research paper. Analyze the paper and produce a JSON object with the following keys:\\n\"\n",
    "        \"- 'summary': A concise abstract-like summary of the paper.\\n\"\n",
    "        \"- 'electrode_materials': A dictionary where each key is one of the following electrode materials: \"\n",
    "        + \", \".join(electrode_keys)\n",
    "        + \". For each material, output 1 if the paper mentions or uses it, otherwise 0.\\n\"\n",
    "        \"- 'functional_electrode_materials': A dictionary where each key is one of the following materials: \"\n",
    "        + \", \".join(functional_keys)\n",
    "        + \". For each material, output 1 if the paper mentions or uses it, otherwise 0.\\n\"\n",
    "        \"- 'benchtop_characterization': A dictionary where each key is one of the following characterization techniques: \"\n",
    "        + \", \".join(characterization_keys)\n",
    "        + \". For each technique, output 1 if the paper mentions it, otherwise 0.\\n\"\n",
    "        \"- 'impedance': If the paper reports an impedance value, extract and output that value as a string; otherwise, output an empty string.\\n\\n\"\n",
    "        \"Ensure the output is valid JSON.\"\n",
    "    )\n",
    "    \n",
    "    prompt_messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_text},\n",
    "        {\"role\": \"user\", \"content\": paper_text}\n",
    "    ]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": prompt_messages,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    \n",
    "    response = requests.post(OPENAI_URL, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"choices\" not in data:\n",
    "        print(\"Error: Unexpected API response format:\")\n",
    "        print(data)\n",
    "        return None\n",
    "    \n",
    "    content = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    # Remove markdown code block markers if present\n",
    "    if content.startswith(\"```\"):\n",
    "        lines = content.splitlines()\n",
    "        if lines[0].strip().startswith(\"```\"):\n",
    "            lines = lines[1:]\n",
    "        if lines and lines[-1].strip() == \"```\":\n",
    "            lines = lines[:-1]\n",
    "        content = \"\\n\".join(lines).strip()\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(content)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing JSON:\", e)\n",
    "        print(\"Content received:\", content)\n",
    "        return None\n",
    "\n",
    "def write_header():\n",
    "    \"\"\"\n",
    "    Writes the CSV header row.\n",
    "    \"\"\"\n",
    "    header = [\"Folder\", \"Summary\"]\n",
    "    header += list(electrode_materials_tally.keys())\n",
    "    header += list(functional_electrode_materials.keys())\n",
    "    header += list(benchtop_characterization.keys())\n",
    "    header.append(\"impedance\")\n",
    "    with open(CSV_FILE, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(header)\n",
    "\n",
    "def append_analysis_to_csv(folder_name, analysis_data):\n",
    "    \"\"\"\n",
    "    Appends the analysis data (including summary and additional columns) to the CSV.\n",
    "    The CSV includes columns for the folder name, summary, each electrode material,\n",
    "    each functional electrode material, each benchtop characterization method, and impedance.\n",
    "    \"\"\"\n",
    "    row = [folder_name, analysis_data.get(\"summary\", \"\")]\n",
    "    # Append electrode materials flags\n",
    "    for key in electrode_materials_tally.keys():\n",
    "        row.append(analysis_data.get(\"electrode_materials\", {}).get(key, 0))\n",
    "    # Append functional electrode materials flags\n",
    "    for key in functional_electrode_materials.keys():\n",
    "        row.append(analysis_data.get(\"functional_electrode_materials\", {}).get(key, 0))\n",
    "    # Append benchtop characterization flags\n",
    "    for key in benchtop_characterization.keys():\n",
    "        row.append(analysis_data.get(\"benchtop_characterization\", {}).get(key, 0))\n",
    "    # Append impedance value\n",
    "    row.append(analysis_data.get(\"impedance\", \"\"))\n",
    "    \n",
    "    with open(CSV_FILE, \"a\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(row)\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(INBOX_PATH):\n",
    "        print(f\"Inbox path does not exist: {INBOX_PATH}\")\n",
    "        return\n",
    "\n",
    "    # Write the header row (this overwrites any existing file)\n",
    "    write_header()\n",
    "\n",
    "    # List all folders in the _inbox\n",
    "    folder_names = [\n",
    "        folder for folder in os.listdir(INBOX_PATH)\n",
    "        if os.path.isdir(os.path.join(INBOX_PATH, folder))\n",
    "    ]\n",
    "\n",
    "    for folder in folder_names:\n",
    "        folder_path = os.path.join(INBOX_PATH, folder)\n",
    "        paper_file = os.path.join(folder_path, \"paper.txt\")\n",
    "\n",
    "        if not os.path.exists(paper_file):\n",
    "            print(f\"Missing paper.txt in folder: {folder}\")\n",
    "            continue\n",
    "\n",
    "        with open(paper_file, \"r\", encoding=\"utf-8\") as pf:\n",
    "            paper_text = pf.read()\n",
    "\n",
    "        analysis = analyze_paper(paper_text)\n",
    "        if analysis is None:\n",
    "            print(f\"Analysis failed for folder: {folder}\")\n",
    "        else:\n",
    "            append_analysis_to_csv(folder, analysis)\n",
    "            print(f\"Processed folder '{folder}' and appended analysis to CSV.\")\n",
    "\n",
    "        # Wait for 6 seconds before processing the next folder\n",
    "        time.sleep(6)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trial 2 - try importing the metrics that I want to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed folder 'Khaldi et al., 2016' and appended analysis to CSV.\n",
      "Processed folder 'Khodagholy et al., 2011' and appended analysis to CSV.\n",
      "Processed folder 'Middya et al., 2021' and appended analysis to CSV.\n",
      "Processed folder 'Middya et al., 2025' and appended analysis to CSV.\n",
      "Processed folder 'Sessolo et al., 2013' and appended analysis to CSV.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve your OpenAI API key from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the path to your _inbox folder and the output CSV file path\n",
    "INBOX_PATH = r\"D:\\OneDrive\\_Carnegie Mellon (CMU)\\60 Academic\\63 Literature Review\\63.002 Literature Review Exports from Zotero\\_inbox\"\n",
    "CSV_FILE = r\"literature_data\\literature_database_v2.csv\"\n",
    "\n",
    "# OpenAI API endpoint for Chat Completions\n",
    "OPENAI_URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "# Default tally keys (if CSV does not exist)\n",
    "default_tally_keys = [\n",
    "    \"Polyethylene Terephthalate (PET)\",\n",
    "    \"Parylene (Parylene-C, Parylene-HT)\",\n",
    "    \"Polyimide (PI)\",\n",
    "    \"SU-8 Photoresist\",\n",
    "    \"Silicon (Si)\",\n",
    "    \"PDMS (Polydimethylsiloxane)\",\n",
    "    \"Gold\",\n",
    "    \"Platinum (Pt)\",\n",
    "    \"Graphene\",\n",
    "    \"Carbon Nanotubes (CNTs)\",\n",
    "    \"Indium Tin Oxide (ITO)\",\n",
    "    \"Titanium (Ti)\",\n",
    "    \"Silver\",\n",
    "    \"PEDOT:PSS\",\n",
    "    \"Nickel\",\n",
    "    \"Aluminum\",\n",
    "    \"Eutectic Gallium–Indium Alloy (EGaIn)\",\n",
    "    \"Chromium (Cr)\",\n",
    "    \"Polycarbonate (PC)\",\n",
    "    \"Styrene-Ethylene-Butylene-Styrene (SEBS)\",\n",
    "    \"Pluronic P123\",\n",
    "    \"Mesoporous Silica Nanoparticles\",\n",
    "    \"Gold Nanorods\",\n",
    "    \"Tungsten\",\n",
    "    \"ZnO Nanowires\",\n",
    "    \"Pyrolytic Carbon\",\n",
    "    # Additional keys (if combined from functional or benchtop groups)\n",
    "    \"SEM Imaging\",\n",
    "    \"AFM (Atomic Force Microscopy)\",\n",
    "    \"XRD (X-ray Diffraction)\",\n",
    "    \"Raman Spectroscopy\",\n",
    "    \"Optical Transparency Measurements\",\n",
    "    \"Mechanical Testing (e.g., bending, strain)\",\n",
    "    \"Photoluminescence Measurements\",\n",
    "    \"Spatial Resolution Testing (Microscopy)\"\n",
    "]\n",
    "\n",
    "def read_tally_keys_from_csv():\n",
    "    \"\"\"\n",
    "    Reads the CSV header and returns a list of tally keys.\n",
    "    Assumes that the first two columns are 'Folder' and 'Summary'\n",
    "    and the last column is the impedance value.\n",
    "    If the CSV file does not exist, returns default_tally_keys.\n",
    "    \"\"\"\n",
    "    if os.path.exists(CSV_FILE):\n",
    "        with open(CSV_FILE, \"r\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            header = next(reader)\n",
    "            if len(header) > 3:\n",
    "                # Exclude 'Folder', 'Summary', and last column (impedance)\n",
    "                return header[2:-1]\n",
    "    return default_tally_keys\n",
    "\n",
    "def analyze_paper(paper_text, tally_keys):\n",
    "    \"\"\"\n",
    "    Sends the paper text to the OpenAI API with a prompt instructing the model to produce a JSON object.\n",
    "    The output JSON includes:\n",
    "      - 'summary': A concise abstract-like summary of the paper.\n",
    "      - 'tally': A dictionary where each key is one of the provided tally_keys.\n",
    "                For each key, output 1 if the paper mentions or uses it, otherwise 0.\n",
    "      - 'impedance': If the paper reports an impedance value, extract and output that value as a string;\n",
    "                     otherwise, output an empty string.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "    }\n",
    "    \n",
    "    prompt_text = (\n",
    "        \"You are given the full text of a research paper. Analyze the paper and produce a JSON object with the following keys:\\n\"\n",
    "        \"- 'summary': A concise abstract-like summary of the paper.\\n\"\n",
    "        \"- 'tally': A dictionary where each key is one of the following: \" \n",
    "        + \", \".join(tally_keys) + \n",
    "        \". For each key, output 1 if the paper mentions or uses it, otherwise 0.\\n\"\n",
    "        \"- 'impedance': If the paper reports an impedance value (e.g. '56 ± 8 kΩ'), extract and output that value as a string; otherwise, output an empty string.\\n\\n\"\n",
    "        \"Ensure the output is valid JSON.\"\n",
    "    )\n",
    "    \n",
    "    prompt_messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_text},\n",
    "        {\"role\": \"user\", \"content\": paper_text}\n",
    "    ]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"o3-mini\",\n",
    "        \"messages\": prompt_messages,\n",
    "    }\n",
    "    \n",
    "    response = requests.post(OPENAI_URL, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"choices\" not in data:\n",
    "        print(\"Error: Unexpected API response format:\")\n",
    "        print(data)\n",
    "        return None\n",
    "    \n",
    "    content = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    # Remove markdown code block markers if present\n",
    "    if content.startswith(\"```\"):\n",
    "        lines = content.splitlines()\n",
    "        if lines[0].strip().startswith(\"```\"):\n",
    "            lines = lines[1:]\n",
    "        if lines and lines[-1].strip() == \"```\":\n",
    "            lines = lines[:-1]\n",
    "        content = \"\\n\".join(lines).strip()\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(content)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing JSON:\", e)\n",
    "        print(\"Content received:\", content)\n",
    "        return None\n",
    "\n",
    "def write_header(tally_keys):\n",
    "    \"\"\"\n",
    "    Writes the CSV header row using the provided tally_keys.\n",
    "    Header columns: Folder, Summary, [tally_keys...], Impedance at 1kHz\n",
    "    \"\"\"\n",
    "    header = [\"Folder\", \"Summary\"] + tally_keys + [\"Impedance at 1kHz\"]\n",
    "    with open(CSV_FILE, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(header)\n",
    "\n",
    "def append_analysis_to_csv(folder_name, analysis_data, tally_keys):\n",
    "    \"\"\"\n",
    "    Appends the analysis data to the CSV.\n",
    "    Data is written in the order of the header:\n",
    "    Folder, Summary, then each key in tally_keys, then Impedance at 1kHz.\n",
    "    \"\"\"\n",
    "    row = [folder_name, analysis_data.get(\"summary\", \"\")]\n",
    "    tally = analysis_data.get(\"tally\", {})\n",
    "    for key in tally_keys:\n",
    "        row.append(tally.get(key, 0))\n",
    "    row.append(analysis_data.get(\"impedance\", \"\"))\n",
    "    \n",
    "    with open(CSV_FILE, \"a\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(row)\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(INBOX_PATH):\n",
    "        print(f\"Inbox path does not exist: {INBOX_PATH}\")\n",
    "        return\n",
    "\n",
    "    # Determine tally keys based on existing CSV header (or defaults)\n",
    "    tally_keys = read_tally_keys_from_csv()\n",
    "    \n",
    "    # Write header row to CSV (this overwrites any existing file)\n",
    "    write_header(tally_keys)\n",
    "    \n",
    "    # List all folders in the _inbox\n",
    "    folder_names = [\n",
    "        folder for folder in os.listdir(INBOX_PATH)\n",
    "        if os.path.isdir(os.path.join(INBOX_PATH, folder))\n",
    "    ]\n",
    "    \n",
    "    for folder in folder_names:\n",
    "        folder_path = os.path.join(INBOX_PATH, folder)\n",
    "        paper_file = os.path.join(folder_path, \"paper.txt\")\n",
    "        \n",
    "        if not os.path.exists(paper_file):\n",
    "            print(f\"Missing paper.txt in folder: {folder}\")\n",
    "            continue\n",
    "        \n",
    "        with open(paper_file, \"r\", encoding=\"utf-8\") as pf:\n",
    "            paper_text = pf.read()\n",
    "        \n",
    "        analysis = analyze_paper(paper_text, tally_keys)\n",
    "        if analysis is None:\n",
    "            print(f\"Analysis failed for folder: {folder}\")\n",
    "        else:\n",
    "            append_analysis_to_csv(folder, analysis, tally_keys)\n",
    "            print(f\"Processed folder '{folder}' and appended analysis to CSV.\")\n",
    "        \n",
    "        # Wait for 6 seconds before processing the next folder\n",
    "        time.sleep(6)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
