{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# import a paper from Zotero, extract data, save to database\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## proof of concept - summarize each paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 114\u001b[0m\n\u001b[0;32m    111\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 114\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[1], line 104\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    101\u001b[0m     paper_text \u001b[38;5;241m=\u001b[39m pf\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Generate the summary using OpenAI\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m summary \u001b[38;5;241m=\u001b[39m generate_summary(paper_text)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Append the summary to the CSV file\u001b[39;00m\n\u001b[0;32m    107\u001b[0m append_summary_to_csv(folder, summary)\n",
      "Cell \u001b[1;32mIn[1], line 54\u001b[0m, in \u001b[0;36mgenerate_summary\u001b[1;34m(paper_text)\u001b[0m\n\u001b[0;32m     32\u001b[0m prompt_messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     33\u001b[0m     {\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m     }\n\u001b[0;32m     48\u001b[0m ]\n\u001b[0;32m     49\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_messages,\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.7\u001b[39m\n\u001b[0;32m     53\u001b[0m }\n\u001b[1;32m---> 54\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(OPENAI_URL, headers\u001b[38;5;241m=\u001b[39mheaders, json\u001b[38;5;241m=\u001b[39mpayload)\n\u001b[0;32m     55\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Debug: Print the full response if \"choices\" is not found\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve your OpenAI API key from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the path to your _inbox folder\n",
    "INBOX_PATH = r\"D:\\OneDrive\\_Carnegie Mellon (CMU)\\60 Academic\\63 Literature Review\\63.002 Literature Review Exports from Zotero\\_inbox\"\n",
    "\n",
    "# OpenAI API endpoint for Chat Completions\n",
    "OPENAI_URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "# Define the output CSV file path\n",
    "CSV_FILE = r\"literature_data\\summaries.csv\"\n",
    "\n",
    "def generate_summary(paper_text):\n",
    "    \"\"\"\n",
    "    Sends the content of paper.txt to the OpenAI Chat Completions endpoint\n",
    "    and returns a summary of the paper. Includes error handling to check\n",
    "    for unexpected API responses.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "    }\n",
    "    prompt_messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are given the full text of a research paper. \"\n",
    "                \"Summarize the paper according to the following instructions: \"\n",
    "                \"1) Provide a concise abstract-like summary. \"\n",
    "                \"2) Highlight the main contributions and conclusions. \"\n",
    "                \"3) Use clear and accessible language. \"\n",
    "                \"Make sure the summary captures the essence of the paper.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": paper_text\n",
    "        }\n",
    "    ]\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": prompt_messages,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    response = requests.post(OPENAI_URL, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Debug: Print the full response if \"choices\" is not found\n",
    "    if \"choices\" not in data:\n",
    "        print(\"Error: Unexpected API response format:\")\n",
    "        print(data)\n",
    "        # Return an empty string or handle as needed\n",
    "        return \"\"\n",
    "    \n",
    "    return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def append_summary_to_csv(folder_name, summary):\n",
    "    \"\"\"\n",
    "    Appends the folder name and summary to a CSV file.\n",
    "    If the file does not exist, it creates one with a header.\n",
    "    \"\"\"\n",
    "    file_exists = os.path.exists(CSV_FILE)\n",
    "    with open(CSV_FILE, \"a\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # Write header if file is new\n",
    "        if not file_exists:\n",
    "            writer.writerow([\"Folder\", \"Summary\"])\n",
    "        writer.writerow([folder_name, summary])\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(INBOX_PATH):\n",
    "        print(f\"Inbox path does not exist: {INBOX_PATH}\")\n",
    "        return\n",
    "\n",
    "    # List all folders in the _inbox\n",
    "    folder_names = [\n",
    "        folder for folder in os.listdir(INBOX_PATH)\n",
    "        if os.path.isdir(os.path.join(INBOX_PATH, folder))\n",
    "    ]\n",
    "\n",
    "    for folder in folder_names:\n",
    "        folder_path = os.path.join(INBOX_PATH, folder)\n",
    "        paper_file = os.path.join(folder_path, \"paper.txt\")\n",
    "\n",
    "        if not os.path.exists(paper_file):\n",
    "            print(f\"Missing paper.txt in folder: {folder}\")\n",
    "            continue\n",
    "\n",
    "        with open(paper_file, \"r\", encoding=\"utf-8\") as pf:\n",
    "            paper_text = pf.read()\n",
    "\n",
    "        # Generate the summary using OpenAI\n",
    "        summary = generate_summary(paper_text)\n",
    "        \n",
    "        # Append the summary to the CSV file\n",
    "        append_summary_to_csv(folder, summary)\n",
    "        print(f\"Processed folder '{folder}' and appended summary to CSV.\")\n",
    "        \n",
    "        # Wait for 6 seconds before processing the next folder\n",
    "        time.sleep(6)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trial 1 - try to sport paper by specific metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve your OpenAI API key from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the path to your _inbox folder and the output CSV file path\n",
    "INBOX_PATH = r\"D:\\OneDrive\\_Carnegie Mellon (CMU)\\60 Academic\\63 Literature Review\\63.002 Literature Review Exports from Zotero\\_inbox\"\n",
    "CSV_FILE = r\"literature_data\\literature_database_v1.csv\"\n",
    "\n",
    "# OpenAI API endpoint for Chat Completions\n",
    "OPENAI_URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "# Dictionaries of materials and characterization methods\n",
    "electrode_materials_tally = {\n",
    "    \"Polyethylene Terephthalate (PET)\": 2,\n",
    "    \"Parylene (Parylene-C, Parylene-HT)\": 7,\n",
    "    \"Polyimide (PI)\": 3,\n",
    "    \"SU-8 Photoresist\": 4,\n",
    "    \"Silicon (Si)\": 4,\n",
    "    \"PDMS (Polydimethylsiloxane)\": 2,\n",
    "    \"Gold\": 5,\n",
    "    \"Platinum (Pt)\": 5,\n",
    "    \"Graphene\": 3,\n",
    "    \"Carbon Nanotubes (CNTs)\": 3,\n",
    "    \"Indium Tin Oxide (ITO)\": 2,\n",
    "    \"Titanium (Ti)\": 2,\n",
    "    \"Silver\": 1,\n",
    "    \"PEDOT:PSS\": 4,\n",
    "    \"Nickel\": 1,\n",
    "    \"Aluminum\": 1,\n",
    "    \"Eutectic Gallium–Indium Alloy (EGaIn)\": 1,\n",
    "    \"Chromium (Cr)\": 3,\n",
    "    \"Polycarbonate (PC)\": 1,\n",
    "    \"Styrene-Ethylene-Butylene-Styrene (SEBS)\": 1,\n",
    "    \"Pluronic P123\": 1,\n",
    "    \"Mesoporous Silica Nanoparticles\": 1,\n",
    "    \"Gold Nanorods\": 1,\n",
    "    \"Tungsten\": 1,\n",
    "    \"ZnO Nanowires\": 1,\n",
    "    \"Pyrolytic Carbon\": 2,\n",
    "}\n",
    "\n",
    "functional_electrode_materials = {\n",
    "    \"Gold\": 5,\n",
    "    \"Platinum (Pt)\": 5,\n",
    "    \"Graphene\": 3,\n",
    "    \"Carbon Nanotubes (CNTs)\": 3,\n",
    "    \"Indium Tin Oxide (ITO)\": 2,\n",
    "    \"Titanium (Ti)\": 2,\n",
    "    \"Silver\": 1,\n",
    "    \"PEDOT:PSS\": 4,\n",
    "    \"Nickel\": 1,\n",
    "    \"Aluminum\": 1,\n",
    "    \"Eutectic Gallium–Indium Alloy (EGaIn)\": 1,\n",
    "    \"Chromium (Cr)\": 3,\n",
    "    \"Pluronic P123\": 1,\n",
    "    \"Mesoporous Silica Nanoparticles\": 1,\n",
    "    \"Gold Nanorods\": 1,\n",
    "    \"Tungsten\": 1,\n",
    "    \"ZnO Nanowires\": 1,\n",
    "    \"Pyrolytic Carbon\": 2\n",
    "}\n",
    "\n",
    "benchtop_characterization = {\n",
    "    \"SEM Imaging\": 5,\n",
    "    \"AFM (Atomic Force Microscopy)\": 2,\n",
    "    \"XRD (X-ray Diffraction)\": 1,\n",
    "    \"Raman Spectroscopy\": 2,\n",
    "    \"Optical Transparency Measurements\": 4,\n",
    "    \"Mechanical Testing (e.g., bending, strain)\": 4,\n",
    "    \"Photoluminescence Measurements\": 1,\n",
    "    \"Spatial Resolution Testing (Microscopy)\": 3\n",
    "}\n",
    "\n",
    "def analyze_paper(paper_text):\n",
    "    \"\"\"\n",
    "    Sends the paper text to the OpenAI API with a prompt instructing the model to produce a JSON output.\n",
    "    The JSON includes a summary, dictionaries for electrode materials, functional electrode materials,\n",
    "    benchtop characterization, and an impedance value if available.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "    }\n",
    "    \n",
    "    electrode_keys = list(electrode_materials_tally.keys())\n",
    "    functional_keys = list(functional_electrode_materials.keys())\n",
    "    characterization_keys = list(benchtop_characterization.keys())\n",
    "    \n",
    "    prompt_text = (\n",
    "        \"You are given the full text of a research paper. Analyze the paper and produce a JSON object with the following keys:\\n\"\n",
    "        \"- 'summary': A concise abstract-like summary of the paper.\\n\"\n",
    "        \"- 'electrode_materials': A dictionary where each key is one of the following electrode materials: \"\n",
    "        + \", \".join(electrode_keys)\n",
    "        + \". For each material, output 1 if the paper mentions or uses it, otherwise 0.\\n\"\n",
    "        \"- 'functional_electrode_materials': A dictionary where each key is one of the following materials: \"\n",
    "        + \", \".join(functional_keys)\n",
    "        + \". For each material, output 1 if the paper mentions or uses it, otherwise 0.\\n\"\n",
    "        \"- 'benchtop_characterization': A dictionary where each key is one of the following characterization techniques: \"\n",
    "        + \", \".join(characterization_keys)\n",
    "        + \". For each technique, output 1 if the paper mentions it, otherwise 0.\\n\"\n",
    "        \"- 'impedance': If the paper reports an impedance value, extract and output that value as a string; otherwise, output an empty string.\\n\\n\"\n",
    "        \"Ensure the output is valid JSON.\"\n",
    "    )\n",
    "    \n",
    "    prompt_messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_text},\n",
    "        {\"role\": \"user\", \"content\": paper_text}\n",
    "    ]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": prompt_messages,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    \n",
    "    response = requests.post(OPENAI_URL, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"choices\" not in data:\n",
    "        print(\"Error: Unexpected API response format:\")\n",
    "        print(data)\n",
    "        return None\n",
    "    \n",
    "    content = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    # Remove markdown code block markers if present\n",
    "    if content.startswith(\"```\"):\n",
    "        lines = content.splitlines()\n",
    "        if lines[0].strip().startswith(\"```\"):\n",
    "            lines = lines[1:]\n",
    "        if lines and lines[-1].strip() == \"```\":\n",
    "            lines = lines[:-1]\n",
    "        content = \"\\n\".join(lines).strip()\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(content)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing JSON:\", e)\n",
    "        print(\"Content received:\", content)\n",
    "        return None\n",
    "\n",
    "def write_header():\n",
    "    \"\"\"\n",
    "    Writes the CSV header row.\n",
    "    \"\"\"\n",
    "    header = [\"Folder\", \"Summary\"]\n",
    "    header += list(electrode_materials_tally.keys())\n",
    "    header += list(functional_electrode_materials.keys())\n",
    "    header += list(benchtop_characterization.keys())\n",
    "    header.append(\"impedance\")\n",
    "    with open(CSV_FILE, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(header)\n",
    "\n",
    "def append_analysis_to_csv(folder_name, analysis_data):\n",
    "    \"\"\"\n",
    "    Appends the analysis data (including summary and additional columns) to the CSV.\n",
    "    The CSV includes columns for the folder name, summary, each electrode material,\n",
    "    each functional electrode material, each benchtop characterization method, and impedance.\n",
    "    \"\"\"\n",
    "    row = [folder_name, analysis_data.get(\"summary\", \"\")]\n",
    "    # Append electrode materials flags\n",
    "    for key in electrode_materials_tally.keys():\n",
    "        row.append(analysis_data.get(\"electrode_materials\", {}).get(key, 0))\n",
    "    # Append functional electrode materials flags\n",
    "    for key in functional_electrode_materials.keys():\n",
    "        row.append(analysis_data.get(\"functional_electrode_materials\", {}).get(key, 0))\n",
    "    # Append benchtop characterization flags\n",
    "    for key in benchtop_characterization.keys():\n",
    "        row.append(analysis_data.get(\"benchtop_characterization\", {}).get(key, 0))\n",
    "    # Append impedance value\n",
    "    row.append(analysis_data.get(\"impedance\", \"\"))\n",
    "    \n",
    "    with open(CSV_FILE, \"a\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(row)\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(INBOX_PATH):\n",
    "        print(f\"Inbox path does not exist: {INBOX_PATH}\")\n",
    "        return\n",
    "\n",
    "    # Write the header row (this overwrites any existing file)\n",
    "    write_header()\n",
    "\n",
    "    # List all folders in the _inbox\n",
    "    folder_names = [\n",
    "        folder for folder in os.listdir(INBOX_PATH)\n",
    "        if os.path.isdir(os.path.join(INBOX_PATH, folder))\n",
    "    ]\n",
    "\n",
    "    for folder in folder_names:\n",
    "        folder_path = os.path.join(INBOX_PATH, folder)\n",
    "        paper_file = os.path.join(folder_path, \"paper.txt\")\n",
    "\n",
    "        if not os.path.exists(paper_file):\n",
    "            print(f\"Missing paper.txt in folder: {folder}\")\n",
    "            continue\n",
    "\n",
    "        with open(paper_file, \"r\", encoding=\"utf-8\") as pf:\n",
    "            paper_text = pf.read()\n",
    "\n",
    "        analysis = analyze_paper(paper_text)\n",
    "        if analysis is None:\n",
    "            print(f\"Analysis failed for folder: {folder}\")\n",
    "        else:\n",
    "            append_analysis_to_csv(folder, analysis)\n",
    "            print(f\"Processed folder '{folder}' and appended analysis to CSV.\")\n",
    "\n",
    "        # Wait for 6 seconds before processing the next folder\n",
    "        time.sleep(6)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trial 2 - try importing the metrics that I want to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve your OpenAI API key from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the path to your _inbox folder and the output CSV file path\n",
    "INBOX_PATH = r\"D:\\OneDrive\\_Carnegie Mellon (CMU)\\60 Academic\\63 Literature Review\\63.002 Literature Review Exports from Zotero\\_inbox\"\n",
    "CSV_FILE = r\"literature_data\\literature_database_v2.csv\"\n",
    "\n",
    "# OpenAI API endpoint for Chat Completions\n",
    "OPENAI_URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "# Default tally keys (if CSV does not exist)\n",
    "default_tally_keys = [\n",
    "    \"Polyethylene Terephthalate (PET)\",\n",
    "    \"Parylene (Parylene-C, Parylene-HT)\",\n",
    "    \"Polyimide (PI)\",\n",
    "    \"SU-8 Photoresist\",\n",
    "    \"Silicon (Si)\",\n",
    "    \"PDMS (Polydimethylsiloxane)\",\n",
    "    \"Gold\",\n",
    "    \"Platinum (Pt)\",\n",
    "    \"Graphene\",\n",
    "    \"Carbon Nanotubes (CNTs)\",\n",
    "    \"Indium Tin Oxide (ITO)\",\n",
    "    \"Titanium (Ti)\",\n",
    "    \"Silver\",\n",
    "    \"PEDOT:PSS\",\n",
    "    \"Nickel\",\n",
    "    \"Aluminum\",\n",
    "    \"Eutectic Gallium–Indium Alloy (EGaIn)\",\n",
    "    \"Chromium (Cr)\",\n",
    "    \"Polycarbonate (PC)\",\n",
    "    \"Styrene-Ethylene-Butylene-Styrene (SEBS)\",\n",
    "    \"Pluronic P123\",\n",
    "    \"Mesoporous Silica Nanoparticles\",\n",
    "    \"Gold Nanorods\",\n",
    "    \"Tungsten\",\n",
    "    \"ZnO Nanowires\",\n",
    "    \"Pyrolytic Carbon\",\n",
    "    # Additional keys (if combined from functional or benchtop groups)\n",
    "    \"SEM Imaging\",\n",
    "    \"AFM (Atomic Force Microscopy)\",\n",
    "    \"XRD (X-ray Diffraction)\",\n",
    "    \"Raman Spectroscopy\",\n",
    "    \"Optical Transparency Measurements\",\n",
    "    \"Mechanical Testing (e.g., bending, strain)\",\n",
    "    \"Photoluminescence Measurements\",\n",
    "    \"Spatial Resolution Testing (Microscopy)\"\n",
    "]\n",
    "\n",
    "def read_tally_keys_from_csv():\n",
    "    \"\"\"\n",
    "    Reads the CSV header and returns a list of tally keys.\n",
    "    Assumes that the first two columns are 'Folder' and 'Summary'\n",
    "    and the last column is the impedance value.\n",
    "    If the CSV file does not exist, returns default_tally_keys.\n",
    "    \"\"\"\n",
    "    if os.path.exists(CSV_FILE):\n",
    "        with open(CSV_FILE, \"r\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            header = next(reader)\n",
    "            if len(header) > 3:\n",
    "                # Exclude 'Folder', 'Summary', and last column (impedance)\n",
    "                return header[2:-1]\n",
    "    return default_tally_keys\n",
    "\n",
    "def analyze_paper(paper_text, tally_keys):\n",
    "    \"\"\"\n",
    "    Sends the paper text to the OpenAI API with a prompt instructing the model to produce a JSON object.\n",
    "    The output JSON includes:\n",
    "      - 'summary': A concise abstract-like summary of the paper.\n",
    "      - 'tally': A dictionary where each key is one of the provided tally_keys.\n",
    "                For each key, output 1 if the paper mentions or uses it, otherwise 0.\n",
    "      - 'impedance': If the paper reports an impedance value, extract and output that value as a string;\n",
    "                     otherwise, output an empty string.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "    }\n",
    "    \n",
    "    prompt_text = (\n",
    "        \"You are given the full text of a research paper. Analyze the paper and produce a JSON object with the following keys:\\n\"\n",
    "        \"- 'summary': A concise abstract-like summary of the paper.\\n\"\n",
    "        \"- 'tally': A dictionary where each key is one of the following: \" \n",
    "        + \", \".join(tally_keys) + \n",
    "        \". For each key, output 1 if the paper mentions or uses it, otherwise 0.\\n\"\n",
    "        \"- 'impedance': If the paper reports an impedance value (e.g. '56 ± 8 kΩ'), extract and output that value as a string; otherwise, output an empty string.\\n\\n\"\n",
    "        \"Ensure the output is valid JSON.\"\n",
    "    )\n",
    "    \n",
    "    prompt_messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_text},\n",
    "        {\"role\": \"user\", \"content\": paper_text}\n",
    "    ]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"o3-mini\",\n",
    "        \"messages\": prompt_messages,\n",
    "    }\n",
    "    \n",
    "    response = requests.post(OPENAI_URL, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"choices\" not in data:\n",
    "        print(\"Error: Unexpected API response format:\")\n",
    "        print(data)\n",
    "        return None\n",
    "    \n",
    "    content = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    # Remove markdown code block markers if present\n",
    "    if content.startswith(\"```\"):\n",
    "        lines = content.splitlines()\n",
    "        if lines[0].strip().startswith(\"```\"):\n",
    "            lines = lines[1:]\n",
    "        if lines and lines[-1].strip() == \"```\":\n",
    "            lines = lines[:-1]\n",
    "        content = \"\\n\".join(lines).strip()\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(content)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing JSON:\", e)\n",
    "        print(\"Content received:\", content)\n",
    "        return None\n",
    "\n",
    "def write_header(tally_keys):\n",
    "    \"\"\"\n",
    "    Writes the CSV header row using the provided tally_keys.\n",
    "    Header columns: Folder, Summary, [tally_keys...], Impedance at 1kHz\n",
    "    \"\"\"\n",
    "    header = [\"Folder\", \"Summary\"] + tally_keys + [\"Impedance at 1kHz\"]\n",
    "    with open(CSV_FILE, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(header)\n",
    "\n",
    "def append_analysis_to_csv(folder_name, analysis_data, tally_keys):\n",
    "    \"\"\"\n",
    "    Appends the analysis data to the CSV.\n",
    "    Data is written in the order of the header:\n",
    "    Folder, Summary, then each key in tally_keys, then Impedance at 1kHz.\n",
    "    \"\"\"\n",
    "    row = [folder_name, analysis_data.get(\"summary\", \"\")]\n",
    "    tally = analysis_data.get(\"tally\", {})\n",
    "    for key in tally_keys:\n",
    "        row.append(tally.get(key, 0))\n",
    "    row.append(analysis_data.get(\"impedance\", \"\"))\n",
    "    \n",
    "    with open(CSV_FILE, \"a\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(row)\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(INBOX_PATH):\n",
    "        print(f\"Inbox path does not exist: {INBOX_PATH}\")\n",
    "        return\n",
    "\n",
    "    # Determine tally keys based on existing CSV header (or defaults)\n",
    "    tally_keys = read_tally_keys_from_csv()\n",
    "    \n",
    "    # Write header row to CSV (this overwrites any existing file)\n",
    "    write_header(tally_keys)\n",
    "    \n",
    "    # List all folders in the _inbox\n",
    "    folder_names = [\n",
    "        folder for folder in os.listdir(INBOX_PATH)\n",
    "        if os.path.isdir(os.path.join(INBOX_PATH, folder))\n",
    "    ]\n",
    "    \n",
    "    for folder in folder_names:\n",
    "        folder_path = os.path.join(INBOX_PATH, folder)\n",
    "        paper_file = os.path.join(folder_path, \"paper.txt\")\n",
    "        \n",
    "        if not os.path.exists(paper_file):\n",
    "            print(f\"Missing paper.txt in folder: {folder}\")\n",
    "            continue\n",
    "        \n",
    "        with open(paper_file, \"r\", encoding=\"utf-8\") as pf:\n",
    "            paper_text = pf.read()\n",
    "        \n",
    "        analysis = analyze_paper(paper_text, tally_keys)\n",
    "        if analysis is None:\n",
    "            print(f\"Analysis failed for folder: {folder}\")\n",
    "        else:\n",
    "            append_analysis_to_csv(folder, analysis, tally_keys)\n",
    "            print(f\"Processed folder '{folder}' and appended analysis to CSV.\")\n",
    "        \n",
    "        # Wait for 6 seconds before processing the next folder\n",
    "        time.sleep(6)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
