{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Main Script to Run\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "1. Open a Paper on Zotero\n",
    "2. Copy the paper into a text file named \"paper.txt\". Save this file into a folder named after the author. (ex. Doe et al., 2015)\n",
    "3. Create annotations, extract them into a text file, and save them as \"notes.txt\"\n",
    "4. Drag & drop the folders into the \"_inbox\" folder, in the same parent folder where all the paper folders are stored. The folders in the _inbox folder will be the ones that the script finds and acts on.\n",
    "5. Run the Script \n",
    "6. A set of Anki flashcards will be generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## complete example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve your OpenAI API key from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the path to your _inbox folder\n",
    "inbox_path = r\"D:\\OneDrive\\_Carnegie Mellon (CMU)\\60 Academic\\63 Literature Review\\63.002 Literature Review Exports from Zotero\\_inbox\"\n",
    "\n",
    "\n",
    "# Update these paths as needed\n",
    "INBOX_PATH = inbox_path  # Ensure this variable is defined appropriately\n",
    "ANKICONNECT_URL = \"http://127.0.0.1:8765\"\n",
    "OPENAI_URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "# Parent deck name\n",
    "PARENT_DECK = \"CMU.63 Literature Review::63.003 Transparent Electrodes\"\n",
    "# PARENT_DECK = \"CMU.63 Literature Review::63.002 Nano-Scale Bioelectronics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Khaldi et al., 2016': {'result': [1741199416658], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Khaldi et al., 2016': {'result': [1741199416721], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Khaldi et al., 2016': {'result': [1741199416784], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Khodagholy et al., 2011': {'result': [1741199419837], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Khodagholy et al., 2011': {'result': [1741199419898], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Khodagholy et al., 2011': {'result': [1741199419959], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Khodagholy et al., 2011': {'result': [1741199420021], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Khodagholy et al., 2011': {'result': [1741199420083], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Khodagholy et al., 2011': {'result': [1741199420145], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2021': {'result': [1741199427090], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2021': {'result': [1741199427165], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2021': {'result': [1741199427216], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2021': {'result': [1741199427282], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2021': {'result': [1741199427348], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2021': {'result': [1741199427415], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2021': {'result': [1741199427468], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2021': {'result': [1741199427531], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2021': {'result': [1741199427598], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2021': {'result': [1741199427655], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2025': {'result': [1741199433028], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2025': {'result': [1741199433088], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2025': {'result': [1741199433151], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2025': {'result': [1741199433221], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2025': {'result': [1741199433275], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2025': {'result': [1741199433343], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2025': {'result': [1741199433404], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2025': {'result': [1741199433464], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Middya et al., 2025': {'result': [1741199433525], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Sessolo et al., 2013': {'result': [1741199436939], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Sessolo et al., 2013': {'result': [1741199437001], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Sessolo et al., 2013': {'result': [1741199437064], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Sessolo et al., 2013': {'result': [1741199437126], 'error': None}\n",
      "Added notecard to deck 'CMU.63 Literature Review::63.003 Transparent Electrodes::Sessolo et al., 2013': {'result': [1741199437187], 'error': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_deck(deck_name):\n",
    "    \"\"\"\n",
    "    Creates a deck in Anki using AnkiConnect. If the deck already exists,\n",
    "    this action will not have any adverse effect.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"action\": \"createDeck\",\n",
    "        \"version\": 6,\n",
    "        \"params\": {\n",
    "            \"deck\": deck_name\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(ANKICONNECT_URL, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "def add_card_to_anki(deck_name, front, back):\n",
    "    \"\"\"\n",
    "    Ensures the deck exists, then adds a Basic card to it.\n",
    "    \"\"\"\n",
    "    create_deck(deck_name)\n",
    "    \n",
    "    payload = {\n",
    "        \"action\": \"addNotes\",\n",
    "        \"version\": 6,\n",
    "        \"params\": {\n",
    "            \"notes\": [\n",
    "                {\n",
    "                    \"deckName\": deck_name,\n",
    "                    \"modelName\": \"Basic\",\n",
    "                    \"fields\": {\n",
    "                        \"Front\": front,\n",
    "                        \"Back\": back\n",
    "                    },\n",
    "                    \"tags\": [\"paper\", \"notecard\"]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(ANKICONNECT_URL, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "def generate_notecards(notes_text):\n",
    "    \"\"\"\n",
    "    Sends the content of notes.txt to the OpenAI Chat Completions endpoint\n",
    "    and returns the raw text containing Q&A pairs formatted as notecards.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "    }\n",
    "    prompt_messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are given annotations from a research paper. \"\n",
    "                \"Create concise question-answer pairs as notecards. \"\n",
    "                \"Each notecard should start with 'Q:' for the question and 'A:' for the answer.\"\n",
    "                \"Make sure to create enough cards to cover all the content in the notes file, \"\n",
    "                \"but keep the total card count no greater than 10-15 cards. \"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": notes_text\n",
    "        }\n",
    "    ]\n",
    "    payload = {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"messages\": prompt_messages,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    response = requests.post(OPENAI_URL, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def parse_q_and_a(generated_text):\n",
    "    \"\"\"\n",
    "    Parses the generated text into a list of (question, answer) tuples.\n",
    "    Expects the format:\n",
    "      Q: Question text\n",
    "      A: Answer text\n",
    "    \"\"\"\n",
    "    lines = generated_text.splitlines()\n",
    "    flashcards = []\n",
    "    question = \"\"\n",
    "    answer = \"\"\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"Q:\"):\n",
    "            if question and answer:\n",
    "                flashcards.append((question, answer))\n",
    "                question, answer = \"\", \"\"\n",
    "            question = line[2:].strip()\n",
    "        elif line.startswith(\"A:\"):\n",
    "            answer = line[2:].strip()\n",
    "    if question and answer:\n",
    "        flashcards.append((question, answer))\n",
    "    return flashcards\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(INBOX_PATH):\n",
    "        print(f\"Inbox path does not exist: {INBOX_PATH}\")\n",
    "        return\n",
    "\n",
    "    # List all folders in the _inbox\n",
    "    folder_names = [\n",
    "        folder for folder in os.listdir(INBOX_PATH)\n",
    "        if os.path.isdir(os.path.join(INBOX_PATH, folder))\n",
    "    ]\n",
    "\n",
    "    for folder in folder_names:\n",
    "        folder_path = os.path.join(INBOX_PATH, folder)\n",
    "        notes_file = os.path.join(folder_path, \"notes.txt\")\n",
    "        paper_file = os.path.join(folder_path, \"paper.txt\")\n",
    "\n",
    "        if not (os.path.exists(notes_file) and os.path.exists(paper_file)):\n",
    "            print(f\"Missing notes.txt or paper.txt in folder: {folder}\")\n",
    "            continue\n",
    "\n",
    "        with open(notes_file, \"r\", encoding=\"utf-8\") as nf:\n",
    "            notes_text = nf.read()\n",
    "\n",
    "        # Generate notecards text via OpenAI\n",
    "        raw_notecards_text = generate_notecards(notes_text)\n",
    "        # Parse the raw text into Q&A pairs\n",
    "        notecards = parse_q_and_a(raw_notecards_text)\n",
    "\n",
    "        # Create the full deck name using the parent deck and the folder name\n",
    "        full_deck_name = f\"{PARENT_DECK}::{folder}\"\n",
    "\n",
    "        for question, answer in notecards:\n",
    "            result = add_card_to_anki(full_deck_name, question, answer)\n",
    "            print(f\"Added notecard to deck '{full_deck_name}': {result}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
